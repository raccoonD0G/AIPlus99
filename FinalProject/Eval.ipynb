{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TMRNblivs1yv"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3320,"status":"ok","timestamp":1747910787583,"user":{"displayName":"김락훈","userId":"17655752783041505657"},"user_tz":-540},"id":"JKWj24xGs3Ak","outputId":"92edb613-57f4-465e-bbe4-88c7c7bb403f"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/Github/AIPlus99/HW6\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks/Github/AIPlus99/HW6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":96680,"status":"ok","timestamp":1747910884266,"user":{"displayName":"김락훈","userId":"17655752783041505657"},"user_tz":-540},"id":"wLVHCRstR1zq","outputId":"04d74e5f-8c2c-4df3-d8c6-694cc52c8cae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n","Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Collecting flash-attn\n","  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.6.0+cu124)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n","Building wheels for collected packages: flash-attn\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187831595 sha256=58853b28a5a926cae14402bfd8d4d93a45ebf8f9e79533f37ab09d0d77a99c05\n","  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n","Successfully built flash-attn\n","Installing collected packages: flash-attn\n","Successfully installed flash-attn-2.7.4.post1\n"]}],"source":["!pip install bitsandbytes\n","!pip install flash-attn --no-build-isolation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["99f49886cf814c2aa27161ee9fb3ce74","bb59a20dcdd54d6884814980af075903","3ce08f6798a04319957c2617808e9687","3a53d957e3664994bb5a3c6bb5f98029","eb774f9689584f89bf47c500b56f81ab","9c700b06c3b449298eaa004e89a207f7","4f07818912f6468aac4d2c1b418640fc","62abf3a4ae904225a34b1c628063f86a","f65fb667d21a4ecaad6e4b0e55bf86e5","a2102d1e5d7f4345a6b589f77cdc8d39","011349a79bc842c8b6908c3b66e3a6e9","9e0a4f2b102c4a4e99732935bbbcfd61","038419ee238f4b1b841a8335eb1c4fdf","affddf361e5642c4b0cc33f03e2474fe","30b5534424014a6abebf9bc522d53e36","5bbf982c4a0a40e4b375444921e5abdc","ef51e73bb1444abfab2b5eb3f3072fea","b0b26c8ff2c84673b6262b9cf3bc38fd","9ac825d090f54c709f45f3d20da2ea74","28aecf184f8d48f7a68328171e878618","ffb3eec7072e4c7cab6f99a106a0b321","5d209693b0eb434eac613677a25b7f10","8d8a5e7a32bb483796e76f3a1c97460a","a7e738243a074b1582f442368724532b","e3ae6d1b8182489f94d90a067850d6e1","4c451f3342304743b52b39f3267b9e76","a53e7bd6509a4f95b291e3e1d154e244","37f04482ffeb496497c9fc74685d6867","ce05808b88b843bab9afb6026cdd73d8","e00f2bdf85b2410189e226c6d30f686b","97f9aaadcf7a4f72b1c289aff412fd42","2a66c88069344c93968660dc2a1413e0","ad23f33a08e64f3cb74c5234a4ccc073","8f1088a2e86e444295d43f98240cbf11","c0297d62c4bd4cbaaec5f89111cf170a","86c614a6074146089a2fabedc8e01c87","9c5611c00aa14a01a208cb5d61effa38","980de4e9723d47b1885b36d59f4c626e","97edbed7c01a4904854395d03a37d966","9e167ddc90a84596a95ac5c33d97acf0","b317e6d9af704564a043e269b7f9cfba","8542ee9b90f140bc980f40ba750a649b","c146f3a2415747398c0dacfe6b725333","7bbc08609b2747ad93bb83853c9560e0","dc867050dc894a7bb077e57adee9fb5d","5788b717d00a46f6bf33333ce1ab6e0d","a6392ce0a97a48939d9e42adecd61a12","9c1237dfc33d42168c66cfc94839d6f4","51fdaf903ede4b039d0373e69b875565","d1cd3708126f446cbec60f7d99d48e47","a153c70a7e0948ea88e56342a11129e9","92ddd787894946af85ab2d755f77d27f","4a093e9a4b6e428b8358d13dcbb42eb5","e5bd6b9fd72a41df971a88c2c4b3b59e","5552576b0150400ab3bb641e85e895c8","ef66d019f9a1491bb387beab0b0af13c","2e415daa7f0948b584e0cbb4d9cb5b15","aadfbc86d9ad411ea5beba3c73d9a626","926b122357ee4f5fa7abad89a52db6be","b00e070b79164ff68bd32c41ff3c6319","d5a4aa91f5684bebb426582d5929f0e4","341983b3073d486b98776a5c7098d86f","2c94d910478c4915912bbc3270a2ebb8","252cf04839db42f39d39b274532cc172","379ebccb5932404ca93992f2ef1141f8","6f5b73f91e6946f1b7ae2e45d4e528eb","ae60cc4e24cb4f1cbd67d3bff89e4c66","3aa3ba19f0264a9d95fc05a6dbe84dc3","4f52a5173a9b494c8ad0fd0d3e9e1439","796ea1cd8f3746fc962936911cff5261","a1e5d005d1ef4cc980f9169b2f8ae3c6","d1fec574503646b0baf5854c04af845f","a8d1d7e0c0864b678f077dec3ccaf9c8","3117dd55aa0e414ebba5970892857c08","58fc9cb1e5394ceeaa6730b17f1b2373","705c1a25e29c4f5487851ed284bf0390","fd2dac6f9f3e41adb5527d94999d75f0","03d83d61962b4505b5ff98c08a46d733","44e6ab3cfa0645ab8e1a69ecdc541d43","6bd2bd97abd0433b850d448872b8c413","5c3bd0e45d2d472d92867ad72a3f6c64","349ffc0fe21f4bd5947df23cf3ca2bb9","28f446b225ce4f1db4f22b0e8fd3c474","862f4f390bfb4e998e95d94d475d2c32","73ff2177e07a44cf86a3584e53b771a0","9eadf6ba21cb4e3f80e35081411d9159","b8ee2e71fe8e4eb5836753e65d75eddc","01b67f59cba443508e565728aa600c06","bbf3c51aaf9a47d2abcb2a527181c6c3","5e4608478b744d249e65a6c657f616ce","01502e7197d24c3eaaf086318afa383a","6f474ab35d594296b3ec3332520bf76f","00fb1d098b4e43dc91dfbfc26c760f59","e311428ac66347768507b098c0bc01ab","815618c637254071aea9b53b955b50fd","bf80e2f94d7140049f65905f14d6bd0a","da063fa4c6924e0ba4caa84c5b6a802a","0ead72d3660f4f5ba6e02ece293dd125","47e0993d37cb4614a0dde43ca627478b","7e0e8266673c4ac3ba9e08623d055ff9","e37ad71cd1794d86a96ed7b9729fb514","24f798ccd9b0491989ff14e1a6a85971","6b39d05ac986487280cf9c7e841fff09","1f0948efbd1f47f2b2b57f6fb2ec08e3","0c4c1bcee07e4c2ab27cf5bde3cd4867","5fd509e8a4314fd98f0fcefae94e952d","77f4faca9c6740b29e3d0d0c313e834e","5d2438ac534a48cd9c49e9c9dc4a566c","bb43c2ed29764488a713979e12264c80","f7a64df7ca984a29b2f33c2f067c7f4a","2b42b39e0b2f42d494deb370f999d398","13aa1c199ea04bfdb2030052fc8ae9b8","289fdf1feb854cce94a3e44925ba3516","12ff71576c4c452fbcde3573892ed5e6","2e82dca3635847a39e3c9a1ccc2db684","d44e0a0335f9403ca9a7c9db4ac9a95e","accb6ebbc30347fb82be2b24d9b1029d","5df1d7d135c94465a7c3c0cba19c7bca","8062136981c34e348e583c6700a01b65","b5b1ca8f922b4cfdb79205d16c251a6b","9a11eb6968da40c194df88714e7ad5f9","8faa74dc2bcf4347bacd0d168eb817d5","489e649cdf1d409f92330ad127f4957c","30f04023dec94d5f9aa1618ceaff7c0a","830ddc13ea1b42c0abdb9904f6b4eb6c","17a3fb6e6deb4ebc839fcee9e0a32648","62d715b955bf48079bc96b1150ad9ac6","2a420faaf08947608233bd64ffc090fa","e7d55bd1888447c58e025ccd780d4f9d","65af3be3cc7c45af949e51e862d0bfec","23d05ca8eddc44a0a5661970be9d3dd7","8a5d5f302f0d4a45910661e5d2ab1d2b","91fbc337ef284e1e852ad85fb502ed60","b7b39865158a4dbdbc8a5721903f80b1","a6f4e4f6c374488d9b3350cba04da262","1f2aad3bed8c4cf1b3ea0ab8f227842b","73dc68cc52164e41ac26527d14c3c153","fe08499c2c3549dbb4c04846305ce94f","d17f6f254f5e48bf84b5c022045f5d1a","df5300263d4e4c45a665bdc5f4f5d83d","47e7edefb4114fdb972c5ce730947b3f","2e25833b3c3e4d1bb57b50c3ac434e3f","3c01a0ae0d744c69a522591ac3041f5a","d3b2e30da12947db9962e0b7ea15223e","ffd99710a9784010b848c949fd22477e","f2603e13e0a34e2c811ec6d01ac28e96","1e14403fe13f48718a8aad914aba87fc","6d07960a7cfe41be8e91383fcd43466f","68221b67954f49d782e1e529326427e7","dcd6fccedb374feca6096df9d656a4eb","5b6590d4f6314f8b900f2929549adc3a","3f88ca0b71134a7fb3bf942411464ab8","6526c96e03814a82b483040147af89e8","4e6582068f47430181b212f4004455e3"]},"executionInfo":{"elapsed":715625,"status":"ok","timestamp":1747911599894,"user":{"displayName":"김락훈","userId":"17655752783041505657"},"user_tz":-540},"id":"FX9UjUySdcM2","outputId":"14a8e8ff-3f56-4e65-c72c-4484a1133bf7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99f49886cf814c2aa27161ee9fb3ce74","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e0a4f2b102c4a4e99732935bbbcfd61","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d8a5e7a32bb483796e76f3a1c97460a","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f1088a2e86e444295d43f98240cbf11","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Initializing new model from base: Qwen/Qwen1.5-0.5B\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc867050dc894a7bb077e57adee9fb5d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef66d019f9a1491bb387beab0b0af13c","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae60cc4e24cb4f1cbd67d3bff89e4c66","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Applying LoRA adaptation...\n","Freezing all parameters except LoRA blocks...\n","Trainable params: 1,572,864 / 465,560,576 (0.34%)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03d83d61962b4505b5ff98c08a46d733","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbf3c51aaf9a47d2abcb2a527181c6c3","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e0e8266673c4ac3ba9e08623d055ff9","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b42b39e0b2f42d494deb370f999d398","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8faa74dc2bcf4347bacd0d168eb817d5","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91fbc337ef284e1e852ad85fb502ed60","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3b2e30da12947db9962e0b7ea15223e","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["No value head to load\n","Loading model + LoRA from checkpoint_1_3b/generator_SFT\n","Freezing all parameters except LoRA blocks...\n","Trainable params: 1,572,864 / 465,560,576 (0.34%)\n","Loaded value head.\n","Loading model + LoRA from checkpoint_1_3b/generator\n","Freezing all parameters except LoRA blocks...\n","Trainable params: 1,572,864 / 465,560,576 (0.34%)\n","Loaded value head.\n","Loading discriminator from ./checkpoint_1_3b/discriminator\n"]},{"name":"stderr","output_type":"stream","text":["Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"]},{"name":"stdout","output_type":"stream","text":["Loaded classifier head from ./checkpoint_1_3b/discriminator/classifier.pt\n"]},{"name":"stderr","output_type":"stream","text":["\r","Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","Evaluating: 100%|██████████| 1/1 [10:15<00:00, 615.63s/it]"]},{"name":"stdout","output_type":"stream","text":["Raw Generator Score : 0.00\n","SFT Generator Score : 86.11\n","PPO Generator Score : 97.59\n","Reference Score     : 100.00\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from code_generator_1_3b import CodeGenerator\n","from requirement_to_code_dataset import get_train_dataloader\n","from code_discriminator import CodeDiscriminator\n","from concurrent.futures import ThreadPoolExecutor\n","import torch\n","from tqdm import tqdm\n","\n","# === 포맷 점수 계산 ===\n","FORMAT_PENALTY_WEIGHT_H = 1.0\n","FORMAT_PENALTY_WEIGHT_CPP = 1.0\n","\n","def compute_format_penalties_h(header_texts):\n","    raw_penalties = torch.tensor([\n","        sum([\n","            -1.0 if not text.strip().startswith(\"```cpp\") else 0.0,\n","            -2.0 if not text.strip().endswith(\"```\") else 0.0,\n","            -1.0 if (\"UCLASS\" not in text and \"USTRUCT\" not in text and \"UINTERFACE\" not in text) else 0.0,\n","            -1.0 if \"#pragma once\" not in text else 0.0,\n","            -1.0 if '#include \"CoreMinimal.h\"' not in text else 0.0,\n","            -1.0 if '.generated.h' not in text else 0.0,\n","            -1.0 if 'GENERATED_BODY()' not in text else 0.0,\n","            -1.0 if '_API' not in text and (\"UCLASS\" in text or \"UINTERFACE\" in text) else 0.0,\n","        ])\n","        for text in header_texts\n","    ], dtype=torch.float32)\n","    return FORMAT_PENALTY_WEIGHT_H * raw_penalties\n","\n","def compute_format_penalties_cpp(cpp_texts):\n","    raw_penalties = torch.tensor([\n","        sum([\n","            -1.0 if not text.strip().startswith(\"```cpp\") else 0.0,\n","            -2.0 if not text.strip().endswith(\"```\") else 0.0,\n","            -6.0 if \"::\" not in text else 0.0,\n","        ])\n","        for text in cpp_texts\n","    ], dtype=torch.float32)\n","    return FORMAT_PENALTY_WEIGHT_CPP * raw_penalties\n","\n","# === 모델 및 데이터 ===\n","test_loader = get_train_dataloader(\"unreal_code_dataset_test.jsonl\", batch_size=90, shuffle=True, limit=90)\n","\n","raw_generator = CodeGenerator()\n","SFT_generator = CodeGenerator(load_path=\"checkpoint_1_3b/generator_SFT\")\n","PPO_generator = CodeGenerator(load_path=\"checkpoint_1_3b/generator\")\n","\n","discriminator = CodeDiscriminator(load_path=\"./checkpoint_1_3b/discriminator\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","discriminator.to(device)\n","raw_generator.to(device)\n","SFT_generator.to(device)\n","PPO_generator.to(device)\n","\n","# === 평가 함수 ===\n","def evaluate_all_generators_threaded(raw_gen, sft_gen, ppo_gen, disc, dataloader, device):\n","    disc.eval()\n","    raw_gen.eval()\n","    sft_gen.eval()\n","    ppo_gen.eval()\n","\n","    raw_scores, sft_scores, ppo_scores, ref_scores = [], [], [], []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n","            prompts = batch[\"requirement\"]\n","            header_gt = batch[\"header_code\"]\n","            cpp_gt = batch[\"cpp_code\"]\n","            reference_code = [h + \"\\n\" + c for h, c in zip(header_gt, cpp_gt)]\n","\n","            raw_code = raw_gen.generate(prompts, return_text=False)\n","            sft_code = sft_gen.generate(prompts, return_text=False)\n","            ppo_code = ppo_gen.generate(prompts, return_text=False)\n","\n","            # === 코드 블럭 추출 ===\n","            h_raw, cpp_raw = raw_code[\"header_texts\"], raw_code[\"cpp_texts\"]\n","            h_sft, cpp_sft = sft_code[\"header_texts\"], sft_code[\"cpp_texts\"]\n","            h_ppo, cpp_ppo = ppo_code[\"header_texts\"], ppo_code[\"cpp_texts\"]\n","            h_ref, cpp_ref = header_gt, cpp_gt\n","\n","            # === Discriminator 평가 ===\n","            def get_disc_scores(h_list, c_list, batch_size=30):\n","                texts = [h + \"\\n\" + c for h, c in zip(h_list, c_list)]\n","                all_outputs = []\n","\n","                for i in range(0, len(texts), batch_size):\n","                    batch_texts = texts[i:i + batch_size]\n","                    with torch.no_grad():\n","                        logits = disc(batch_texts)  # (B, 1) or (B,)\n","                        probs = torch.sigmoid(logits)\n","                        adjusted = 2 * probs - 1.0  # [-1.0, 1.0]\n","                        all_outputs.append(adjusted.squeeze().cpu())\n","\n","                return torch.cat(all_outputs, dim=0)\n","\n","            raw_output = get_disc_scores(h_raw, cpp_raw)\n","            sft_output = get_disc_scores(h_sft, cpp_sft)\n","            ppo_output = get_disc_scores(h_ppo, cpp_ppo)\n","            ref_output = get_disc_scores(h_ref, cpp_ref)\n","\n","            # === 포맷 패널티 계산 ===\n","            penalty_raw = compute_format_penalties_h(h_raw).mean() + compute_format_penalties_cpp(cpp_raw).mean()\n","            penalty_sft = compute_format_penalties_h(h_sft).mean() + compute_format_penalties_cpp(cpp_sft).mean()\n","            penalty_ppo = compute_format_penalties_h(h_ppo).mean() + compute_format_penalties_cpp(cpp_ppo).mean()\n","            penalty_ref = compute_format_penalties_h(h_ref).mean() + compute_format_penalties_cpp(cpp_ref).mean()\n","\n","            score_raw = raw_output + penalty_raw\n","            score_sft = sft_output + penalty_sft\n","            score_ppo = ppo_output + penalty_ppo\n","            score_ref = ref_output + penalty_ref\n","\n","            score_range = (score_ref - score_raw).clamp(min=1e-6)\n","            sft_score = ((score_sft - score_raw) / score_range * 100)\n","            ppo_score = ((score_ppo - score_raw) / score_range * 100)\n","\n","            raw_scores.append(torch.tensor(0.0))\n","            sft_scores.append(sft_score)\n","            ppo_scores.append(ppo_score)\n","            ref_scores.append(torch.tensor(100.0))\n","\n","    return {\n","        \"raw\": torch.stack(raw_scores).mean().item(),\n","        \"sft\": torch.stack(sft_scores).mean().item(),\n","        \"ppo\": torch.stack(ppo_scores).mean().item(),\n","        \"ref\": torch.stack(ref_scores).mean().item(),\n","    }\n","\n","# === 평가 실행 ===\n","results = evaluate_all_generators_threaded(raw_generator, SFT_generator, PPO_generator, discriminator, test_loader, device)\n","\n","# === 결과 출력 ===\n","print(f\"Raw Generator Score : {results['raw']:.2f}\")\n","print(f\"SFT Generator Score : {results['sft']:.2f}\")\n","print(f\"PPO Generator Score : {results['ppo']:.2f}\")\n","print(f\"Reference Score     : {results['ref']:.2f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNvH0rH2z66dfa/IbHpRXuH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}