{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPxnMYhzRvLfBqGqM3cQE+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"05DlaYTKyQdT"},"outputs":[],"source":["import os\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torchvision.datasets import CIFAR100\n","\n","class ResidualCNNBlock(nn.Module):\n","    def __init__(self, channels, dropout=0.2):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(channels),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout2d(dropout),\n","            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(channels),\n","        )\n","        self.activation = nn.LeakyReLU(0.1)\n","\n","    def forward(self, x):\n","        return self.activation(x + self.block(x))\n","\n","class ImageEncoder(nn.Module):\n","    def __init__(self, embedding_dim=768, weight_path=\"trained_image_autoencoder\"):\n","        super().__init__()\n","\n","        # Encoder 구조\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout2d(0.2),\n","\n","            ResidualCNNBlock(32, dropout=0.2),\n","\n","            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout2d(0.2),\n","\n","            ResidualCNNBlock(64, dropout=0.2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout2d(0.2),\n","\n","            ResidualCNNBlock(128, dropout=0.2),\n","\n","            nn.AdaptiveAvgPool2d((4, 4)),\n","        )\n","\n","        self.projector = nn.Sequential(\n","            nn.Linear(2048, 512),\n","            nn.LayerNorm(512),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.2),\n","\n","            nn.Linear(512, 512),\n","            nn.LayerNorm(512),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.2),\n","\n","            nn.Linear(512, embedding_dim),\n","            nn.LayerNorm(embedding_dim),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.2),\n","        )\n","\n","        # 가중치 로드\n","        encoder_path = os.path.join(weight_path, \"encoder.pt\")\n","        projector_path = os.path.join(weight_path, \"projector.pt\")\n","\n","        if os.path.exists(encoder_path) and os.path.exists(projector_path):\n","            self.encoder.load_state_dict(torch.load(encoder_path, map_location=\"cpu\"))\n","            self.projector.load_state_dict(torch.load(projector_path, map_location=\"cpu\"))\n","            print(f\"가중치를 받아옵니다 '{weight_path}'\")\n","        else:\n","            print(f\"가중치가 없습니다. 처음부터 학습합니다\")\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = x.view(x.size(0), -1)\n","        z = self.projector(x)\n","        return z  # (B, 768)\n","\n","\n","class Autoencoder(nn.Module):\n","    def __init__(self, embedding_dim=768):\n","        super().__init__()\n","\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout2d(0.2),\n","\n","            ResidualCNNBlock(32, dropout=0.2),\n","\n","            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout2d(0.2),\n","\n","            ResidualCNNBlock(64, dropout=0.2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout2d(0.2),\n","\n","            ResidualCNNBlock(128, dropout=0.2),\n","\n","            nn.AdaptiveAvgPool2d((4, 4)),\n","        )\n","\n","        self.projector = nn.Sequential(\n","            nn.Linear(2048, 512),\n","            nn.LayerNorm(512),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.2),\n","\n","            nn.Linear(512, 512),\n","            nn.LayerNorm(512),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.2),\n","\n","            nn.Linear(512, embedding_dim),\n","            nn.LayerNorm(embedding_dim),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.2),\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            nn.Linear(768, 128 * 28 * 28),\n","            nn.LayerNorm(128 * 28 * 28),\n","            nn.LeakyReLU(0.1),\n","            nn.Unflatten(1, (128, 28, 28)),\n","\n","            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n","            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.1),\n","\n","            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n","            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.1),\n","\n","            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n","            nn.Conv2d(32, 3, kernel_size=3, padding=1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = x.view(x.size(0), -1)\n","        z = self.projector(x)\n","        out = self.decoder(z)\n","        return out, z\n","\n","class ImageFolderDataset(Dataset):\n","    def __init__(self, folder, transform=None):\n","        self.paths = [os.path.join(folder, fname) for fname in os.listdir(folder) if fname.endswith('.png')]\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.paths[idx]).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, image\n","\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])\n","\n","if __name__ == \"__main__\":\n","    dataset = CIFAR100(root=\".\", download=True, transform=transform)\n","    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n","\n","    model = Autoencoder().to(\"cuda\")\n","    loss_fn = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","    # Training loop\n","    n_epochs = 10\n","    model.train()\n","    for epoch in range(n_epochs):\n","        total_loss = 0\n","        for imgs, targets in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n","            imgs, targets = imgs.to(\"cuda\"), targets.to(\"cuda\")\n","            optimizer.zero_grad()\n","            outputs, _ = model(imgs)\n","            loss = loss_fn(outputs, imgs)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        tqdm.write(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n","\n","    os.makedirs(\"trained_image_autoencoder\", exist_ok=True)\n","    torch.save(model.encoder.state_dict(), \"trained_image_autoencoder/encoder.pt\")\n","    torch.save(model.projector.state_dict(), \"trained_image_autoencoder/projector.pt\")"]}]}